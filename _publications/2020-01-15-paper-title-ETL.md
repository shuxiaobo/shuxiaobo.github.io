---
title: "Joint Extraction of Entities and Relations Based on a Novel Decomposition Strategy"
collection: publications
permalink: /publication/2020-01-15-paper-title-ETL
excerpt: 'Incorporating lexicons into character-level Chinese NER by lattices is proven effective to exploit rich word boundary information. Previous work has extended RNNs to consume lattice inputs and achieved great success. However, due to the inherently sequential nature, this method precludes batch computation and sufficient semantic interaction. In this paper, we propose PLTE, an extension of Transformer encoder that is tailored for Chinese Languge Tasks. PLTE utilizes the lattice-aware self-attention coupled with relation embeddings to explore relative positional information in the lattice. It also learns a porous attention distribution to augment localness modeling and maintain the strength of capturing the rich long-term dependencies. Experimental results show that PLTE performs up to 11.4 times faster than state-of-the-art methods while realizing better performance. We also demonstrate that using BERT representations further brings significant improvement.'
date: 2020-01-15
venue: 'ECAI 2020'
paperurl: 'http://shuxiaobo.github.io/files/ETL.pdf'
citation: 'Bowen Yu, Zhenyu Zhang, Xiaobo Shu, Tingwen Liu, Yubin Wang, Bin Wang, Sujian Li.'
---
[Download paper here](http://shuxiaobo.github.io/files/ETL.pdf)

